{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from random import shuffle, sample, choice\n",
    "import numpy as np\n",
    "from scipy.signal import convolve\n",
    "from scipy.io import loadmat\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from librosa import load, resample, get_samplerate, get_duration\n",
    "import soundfile as sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_dir = Path('/home/gmvwasse/MS-SNSD/clean_train')\n",
    "noise_dir = Path('/home/gmvwasse/MS-SNSD/noise_train')\n",
    "RIR_dir = Path('/project/RIRs')\n",
    "\n",
    "SNRs = [-10, -5, 0, 5, 10, 20, 30, 40]\n",
    "\n",
    "validation_frac = 0.1\n",
    "training_frac = 1 - validation_frac\n",
    "\n",
    "max_size = 37800\n",
    "\n",
    "output_dir = Path('/project/EHNet/WAVs/dataset_reverb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(x):\n",
    "    return np.sum(np.square(x))\n",
    "\n",
    "def SNR(s, n):\n",
    "    return 10*math.log10(power(s)/power(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_convolve(speech_wav, RIR_path, SNRs):\n",
    "    while True:\n",
    "        try:\n",
    "            RIR = loadmat(RIR_path)\n",
    "        except IOError:\n",
    "            continue\n",
    "        break\n",
    "    RIR = RIR['h_air'][0]\n",
    "    speech_wav_upsampled = resample(speech_wav, 16000, 48000, res_type='kaiser_fast')\n",
    "    convolved = convolve(speech_wav_upsampled, RIR)\n",
    "    convolved = convolved[:3*len(speech_wav)]\n",
    "    convolved_downsampled = resample(convolved, 48000, 16000, res_type='kaiser_fast')\n",
    "    current_SNR = SNR(speech_wav, convolved_downsampled)\n",
    "    alpha = 1/math.sqrt(math.pow(10, (choice(SNRs) - current_SNR)/10))\n",
    "    return speech_wav + alpha * convolved_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def snr_mixer(clean, noise, snr):\n",
    "    # Normalizing to -25 dB FS\n",
    "    rmsclean = (clean**2).mean()**0.5\n",
    "    scalarclean = 10 ** (-25 / 20) / rmsclean\n",
    "    clean = clean * scalarclean\n",
    "    rmsclean = (clean**2).mean()**0.5\n",
    "\n",
    "    rmsnoise = (noise**2).mean()**0.5\n",
    "    scalarnoise = 10 ** (-25 / 20) /rmsnoise\n",
    "    noise = noise * scalarnoise\n",
    "    rmsnoise = (noise**2).mean()**0.5\n",
    "    \n",
    "    # Set the noise level for a given SNR\n",
    "    noisescalar = np.sqrt(rmsclean / (10**(snr/10)) / rmsnoise)\n",
    "    noisenewlevel = noise * noisescalar\n",
    "    noisyspeech = clean + noisenewlevel\n",
    "    return noisyspeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavs(speech_dir, noise_dir, RIR_dir, speech_filenames, noise_filenames, SNRs, output_path, max_size):\n",
    "    clean_output_path = output_path.joinpath('clean')\n",
    "    noisy_output_path = output_path.joinpath('noisy')\n",
    "    if not Path.exists(clean_output_path):\n",
    "        os.makedirs(clean_output_path)\n",
    "    if not Path.exists(noisy_output_path):\n",
    "        os.makedirs(noisy_output_path)\n",
    "        \n",
    "    RIR_filenames = os.listdir(RIR_dir)\n",
    "    \n",
    "    pbar = tqdm(total=max_size)\n",
    "    \n",
    "    num_samples = 0\n",
    "    filecounter = 0\n",
    "    while num_samples < max_size:\n",
    "        ##------- Getting speech -------##\n",
    "        idx_s = np.random.randint(0, np.size(speech_filenames))\n",
    "        path_speech = speech_dir.joinpath(speech_filenames[idx_s])\n",
    "        if get_samplerate(path_speech) == 16000:\n",
    "            speech_wav, _ = load(path_speech, sr=None, mono=True)\n",
    "        else:\n",
    "            speech_wav, _ = load(path_speech, sr=16000, mono=True, res_type='kaiser_fast')\n",
    "        \n",
    "        # make sure all WAVs are 128000 samples (8s) long\n",
    "        length_difference = 128000 - len(speech_wav)\n",
    "        while length_difference > 0:\n",
    "            idx_s = idx_s + 1\n",
    "            if idx_s >= np.size(speech_filenames)-1:\n",
    "                idx_s = np.random.randint(0, np.size(speech_filenames))\n",
    "                \n",
    "            path_speech = speech_dir.joinpath(speech_filenames[idx_s])\n",
    "            while True:\n",
    "                try:\n",
    "                    if get_samplerate(path_speech) == 16000:\n",
    "                        new_speech_wav, _ = load(path_speech, sr=None, mono=True)\n",
    "                    else:\n",
    "                        new_speech_wav, _ = load(path_speech, sr=16000, mono=True, res_type='kaiser_fast')\n",
    "                except RuntimeError:\n",
    "                    continue\n",
    "                break\n",
    "            \n",
    "            cleanconcat = np.append(speech_wav, np.zeros(int(16000*0.2))) # 0.2 seconds of silence between utterances\n",
    "            speech_wav = np.append(cleanconcat, new_speech_wav)\n",
    "            \n",
    "            length_difference = 128000 - len(speech_wav)\n",
    "        \n",
    "        if length_difference == 0:\n",
    "            pass\n",
    "        if length_difference < 0:\n",
    "            start = np.random.randint(0, -length_difference)\n",
    "            speech_wav = speech_wav[start:start+128000]\n",
    "            \n",
    "        assert len(speech_wav) == 128000, 'Speech waveform has ' + str(len(speech_wav)) + ' samples instead of 128000 samples!'\n",
    "        \n",
    "        RIR_filenames = [filename for filename in RIR_filenames if filename.endswith('.mat')]\n",
    "        RIR_path = RIR_dir.joinpath(choice(RIR_filenames))\n",
    "        speech_convolved_wav = resample_convolve(speech_wav, RIR_path, [20, 30, 40])\n",
    "        \n",
    "        # normalize speech part to -25dBFS\n",
    "        rms = (speech_convolved_wav ** 2).mean() ** 0.5\n",
    "        scalar = 10 ** (-25 / 20) / (rms)\n",
    "        speech_convolved_wav = speech_convolved_wav * scalar\n",
    "        speech_wav = speech_wav * scalar\n",
    "        \n",
    "\n",
    "        ##------- Adding noise -------##\n",
    "        idx_n = np.random.randint(0, np.size(noise_filenames))\n",
    "        path_noise = noise_dir.joinpath(noise_filenames[idx_n])\n",
    "        while True:\n",
    "            try:\n",
    "                if get_samplerate(path_noise) == 16000:\n",
    "                    noise_wav, _ = load(path_noise, sr=None, mono=True)\n",
    "                else:\n",
    "                    noise_wav, _ = load(path_noise, sr=16000, mono=True, res_type='kaiser_fast')\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "            break\n",
    "\n",
    "        # normalize noise part to -25dBFS\n",
    "        rms = (noise_wav ** 2).mean() ** 0.5\n",
    "        scalar = 10 ** (-25 / 20) / (rms)\n",
    "        noise_wav = noise_wav * scalar\n",
    "\n",
    "        length_difference = len(speech_wav) - len(noise_wav)\n",
    "        if length_difference == 0:\n",
    "            pass\n",
    "        if length_difference > 0:\n",
    "            print(\"Noise was shorter than 8s!\")\n",
    "            continue\n",
    "        if length_difference < 0:\n",
    "            start = np.random.randint(0, -length_difference)\n",
    "            noise_wav = noise_wav[start:start+len(speech_wav)]\n",
    "\n",
    "        desired_SNR = choice(SNRs)\n",
    "        noisy_speech_wav = snr_mixer(speech_convolved_wav, noise_wav, desired_SNR)\n",
    "\n",
    "        if np.max(np.abs(noisy_speech_wav)) > 1: # skip if we are clipping\n",
    "            continue\n",
    "\n",
    "        filecounter = filecounter + 1\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                clean_speech_filename = clean_output_path.joinpath(str(filecounter) + '.wav')\n",
    "                sf.write(clean_speech_filename, speech_wav, 16000)\n",
    "\n",
    "                noisy_speech_filename = noisy_output_path.joinpath(str(filecounter) + '+SNR' + str(desired_SNR) + 'dB' + '.wav')\n",
    "                sf.write(noisy_speech_filename, noisy_speech_wav, 16000)\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "            break\n",
    "        \n",
    "        num_samples += 1\n",
    "        pbar.update(1)\n",
    "        \n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_generate_wavs(speech_dir, noise_dir, RIR_dir, SNRs, validation_frac, training_frac, max_size, output_dir):\n",
    "    speech_filenames = os.listdir(speech_dir)\n",
    "    speech_filenames = [filename for filename in speech_filenames if filename.endswith('.wav')]\n",
    "    shuffle(speech_filenames)\n",
    "    \n",
    "    noise_filenames = os.listdir(noise_dir)\n",
    "    noise_filenames = [filename for filename in noise_filenames if filename.endswith('.wav') and get_duration(filename=noise_dir.joinpath(filename)) >= 8]\n",
    "    shuffle(noise_filenames)\n",
    "    \n",
    "    print('Using', len(speech_filenames), 'speech files.')\n",
    "    print('Using', len(noise_filenames), 'noise files.')\n",
    "    \n",
    "\n",
    "    speech_train, speech_val = np.split(speech_filenames, [int(training_frac*len(speech_filenames))])\n",
    "    \n",
    "    training_output_path = output_dir.joinpath('training')\n",
    "    val_output_path = output_dir.joinpath('validation')\n",
    "    \n",
    "    # generate training set\n",
    "    generate_wavs(speech_dir, noise_dir, RIR_dir, speech_train, noise_filenames, SNRs, training_output_path, int(max_size * training_frac))\n",
    "    \n",
    "    # generate validation set\n",
    "    generate_wavs(speech_dir, noise_dir, RIR_dir, speech_val, noise_filenames, SNRs, val_output_path, int(max_size * validation_frac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 23075 speech files.\n",
      "Using 128 noise files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246d763f6d0d41faa29b148974d8e864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=34020.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OSError",
     "evalue": "Reader needs file name or open file-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/project/RIRs/air_binaural_lecture_0_0_6.mat'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0559bf2b39e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msplit_generate_wavs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRIR_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSNRs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-e02917fc5fc8>\u001b[0m in \u001b[0;36msplit_generate_wavs\u001b[0;34m(speech_dir, noise_dir, RIR_dir, SNRs, validation_frac, training_frac, max_size, output_dir)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# generate training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mgenerate_wavs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRIR_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeech_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSNRs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_output_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtraining_frac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# generate validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-39506401d481>\u001b[0m in \u001b[0;36mgenerate_wavs\u001b[0;34m(speech_dir, noise_dir, RIR_dir, speech_filenames, noise_filenames, SNRs, output_path, max_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mRIR_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRIR_filenames\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mRIR_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRIR_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRIR_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mspeech_convolved_wav\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresample_convolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspeech_wav\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRIR_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# normalize speech part to -25dBFS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3fdbc52db5f2>\u001b[0m in \u001b[0;36mresample_convolve\u001b[0;34m(speech_wav, RIR_path, SNRs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mRIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRIR_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36mloadmat\u001b[0;34m(file_name, mdict, appendmat, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \"\"\"\n\u001b[1;32m    215\u001b[0m     \u001b[0mvariable_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'variable_names'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0mMR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat_reader_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0mmatfile_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file_context\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappendmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopened\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/scipy/io/matlab/mio.py\u001b[0m in \u001b[0;36m_open_file\u001b[0;34m(file_like, appendmat, mode)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reader needs file name or open file-like object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Reader needs file name or open file-like object"
     ]
    }
   ],
   "source": [
    "split_generate_wavs(speech_dir, noise_dir, RIR_dir, SNRs, validation_frac, training_frac, max_size, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
