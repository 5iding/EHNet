{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from random import randrange, shuffle, sample\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speech_dir = Path('./WAVs/speech')\n",
    "speech_dir = Path('/home/guillaume/Nextcloud/Thesis_Guillaume/Datasets/Dry Speech/Parsed TIMIT/parsed_output')\n",
    "noise_dir = Path('./WAVs/noise')\n",
    "\n",
    "SNRs = [-5, 0, 5, 10, 25]\n",
    "\n",
    "testing_frac = 0.1\n",
    "validation_frac = 0.1\n",
    "training_frac = 1 - testing_frac - validation_frac\n",
    "\n",
    "max_size = 10000\n",
    "\n",
    "output_dir = Path('./WAVs/dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(x):\n",
    "    return np.sum(np.square(x))\n",
    "\n",
    "def SNR(s, n):\n",
    "    return 10*math.log10(power(s)/power(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_wavs(speech_dir, noise_dir, speech_filenames, noise_filenames, SNRs, output_path):\n",
    "    clean_output_path = output_path.joinpath('clean')\n",
    "    noisy_output_path = output_path.joinpath('noisy')\n",
    "    if not Path.exists(clean_output_path):\n",
    "        os.makedirs(clean_output_path)\n",
    "    if not Path.exists(noisy_output_path):\n",
    "        os.makedirs(noisy_output_path)\n",
    "    \n",
    "    for filename_speech in tqdm(speech_filenames):\n",
    "        sample_rate, speech_wav = wavfile.read(speech_dir.joinpath(filename_speech))\n",
    "        assert sample_rate == 16000, 'Sample rate is not 16kHz!'\n",
    "        \n",
    "        # make sure all WAVs are 64000 samples (4s) long\n",
    "        length_difference = 64000 - len(speech_wav)\n",
    "        if length_difference > 0:\n",
    "            start = randrange(0, length_difference)\n",
    "            speech_wav = np.pad(speech_wav, (start, length_difference - start))\n",
    "        if length_difference < 0:\n",
    "            start = randrange(0, -length_difference)\n",
    "            speech_wav = speech_wav[start:start+64000]\n",
    "            \n",
    "        assert len(speech_wav) == 64000, 'Speech waveform has ' + str(len(speech_wav)) + ' samples instead of 64000 samples!'\n",
    "        \n",
    "        clean_speech_filename = clean_output_path.joinpath(filename_speech.rsplit( \".\", 1 )[0].replace('_', '') + '.wav')\n",
    "        wavfile.write(clean_speech_filename, 16000, speech_wav.astype(np.int16))\n",
    "        speech_wav = speech_wav/2**15\n",
    "\n",
    "        for filename_noise in noise_filenames:\n",
    "            sample_rate, noise_wav = wavfile.read(noise_dir.joinpath(filename_noise))\n",
    "            assert sample_rate == 16000, 'Sample rate is not 16kHz!'\n",
    "            noise_wav = noise_wav/2**15\n",
    "\n",
    "            current_SNR = SNR(speech_wav, noise_wav)\n",
    "\n",
    "            length_difference = len(speech_wav) - len(noise_wav)\n",
    "\n",
    "            for desired_SNR in SNRs:\n",
    "                alpha = 1/math.sqrt( math.pow(10, (desired_SNR - current_SNR)/10)) # alpha so the SNR matches the wanted SNR\n",
    "                if length_difference == 0:\n",
    "                    noisy_speech_wav = speech_wav + alpha * noise_wav\n",
    "                if length_difference > 0:\n",
    "                    start = randrange(0, length_difference)\n",
    "                    noisy_speech_wav = speech_wav + alpha * np.pad(noise_wav, (start, length_difference - start))\n",
    "                if length_difference < 0:\n",
    "                    start = randrange(0, -length_difference)\n",
    "                    noisy_speech_wav = speech_wav + alpha * noise_wav[start:start+len(speech_wav)]\n",
    "\n",
    "                noisy_speech_wav = noisy_speech_wav * 2**15\n",
    "                noisy_speech_wav = noisy_speech_wav.astype(np.int16)\n",
    "                noisy_speech_filename = noisy_output_path.joinpath(filename_speech.rsplit( \".\", 1 )[0].replace('_', '') + '_' + filename_noise.rsplit( \".\", 1 )[0].replace('_', '') + '_SNR' + str(desired_SNR) + 'dB' + '.wav')\n",
    "                wavfile.write(noisy_speech_filename, 16000, noisy_speech_wav)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_generate_wavs(speech_dir, noise_dir, SNRs, testing_frac, validation_frac, training_frac, max_size, output_dir):\n",
    "    assert testing_frac + validation_frac + training_frac == 1, 'Split fractions do not sum to 1!'\n",
    "    \n",
    "    speech_filenames = os.listdir(speech_dir)\n",
    "    shuffle(speech_filenames)\n",
    "    \n",
    "    noise_filenames = os.listdir(noise_dir)\n",
    "    shuffle(noise_filenames)\n",
    "    \n",
    "    if max_size:\n",
    "        if len(speech_filenames) * len(noise_filenames) * len(SNRs) > max_size:\n",
    "            reduce_factor = max_size / (len(SNRs) * len(speech_filenames) * len(noise_filenames))\n",
    "            speech_filenames = sample(speech_filenames, int(len(speech_filenames) * reduce_factor))\n",
    "    \n",
    "    print('Will output', len(speech_filenames) * len(noise_filenames) * len(SNRs), 'WAV files.')\n",
    "    \n",
    "\n",
    "    speech_train, speech_val, speech_test = np.split(speech_filenames,\n",
    "                                                     [int(training_frac*len(speech_filenames)), int((training_frac + validation_frac)*len(speech_filenames))])\n",
    "\n",
    "\n",
    "    noise_seen, noise_unseen = np.split(noise_filenames,\n",
    "                                        [int(training_frac*len(noise_filenames))])\n",
    "    \n",
    "    training_output_path = output_dir.joinpath('training')\n",
    "    val_output_path = output_dir.joinpath('validation')\n",
    "    test_seen_noise_output_path = output_dir.joinpath('testing_seen_noise')\n",
    "    test_unseen_noise_output_path = output_dir.joinpath('testing_unseen_noise')\n",
    "    \n",
    "    # generate training set\n",
    "    generate_wavs(speech_dir, noise_dir, speech_train, noise_seen, SNRs, training_output_path)\n",
    "    \n",
    "    # generate validation set\n",
    "    generate_wavs(speech_dir, noise_dir, speech_val, noise_seen, SNRs, val_output_path)\n",
    "    \n",
    "    # generate testing set on seen noise\n",
    "    generate_wavs(speech_dir, noise_dir, speech_test, noise_seen, SNRs, test_seen_noise_output_path)\n",
    "    \n",
    "    # generate testing set on seen noise\n",
    "    generate_wavs(speech_dir, noise_dir, speech_test, noise_unseen, SNRs, test_unseen_noise_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will output 9975 WAV files.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60912f1905f747abaa904e188d762cdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=76.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a155f646b3b44e72aebf80b284ebe4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c2772ba4a96439ebd0c3c48785e0912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210ddbdc9c994cbfa5b7868631a1dfc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split_generate_wavs(speech_dir, noise_dir, SNRs, testing_frac, validation_frac, training_frac, max_size, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
